{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae2b70f",
   "metadata": {},
   "source": [
    "# Project Overview: Model Packaging and Deployment Formats\n",
    "\n",
    "This project demonstrates how to package and deploy machine learning models using various formats and frameworks. The goal is to explore the trade-offs, compatibility, and performance characteristics of each approach to better inform deployment choices in production settings.\n",
    "\n",
    "The packaging formats and frameworks covered in this notebook include:\n",
    "\n",
    "- **ONNX** – Open Neural Network Exchange format for cross-framework interoperability  \n",
    "- **TorchScript** – PyTorch-native serialization for optimized model execution  \n",
    "- **PyTorch JIT** – Just-In-Time compilation for efficient model inference  \n",
    "- **TensorRT** – NVIDIA’s high-performance deep learning inference optimizer  \n",
    "- **TensorFlow SavedModel** – Standard format for TensorFlow model export and deployment  \n",
    "- **JAX** – High-performance numerical computing with composable function transformations\n",
    "\n",
    "This comparison is aimed at practitioners who need to understand how to efficiently serialize, deploy, and run models in various production environments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eac89914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 13:55:13,883 - onnx_export - INFO - Starting ONNX export...\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Setup logger\n",
    "logger = logging.getLogger(\"onnx_export\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Add a StreamHandler if it doesn't exist\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# Test the logger\n",
    "logger.info(\"Starting ONNX export...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73c67834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m181 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m (from file:///Users/dimda/torch-t\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1mtorch-to-any\u001b[0m\u001b[2m==0.1.0 (from file:///Users/dimda/torch-to-any/torch-to-any)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv add onnx onnxscript torch onnxruntime torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "987d11e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ImageClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1a38ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `ImageClassifierModel([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `ImageClassifierModel([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n"
     ]
    }
   ],
   "source": [
    "# Setup a logger\n",
    "\n",
    "torch_model = ImageClassifierModel()\n",
    "# Create example inputs for exporting the model. The inputs should be a tuple of tensors.\n",
    "example_inputs = (torch.randn(1, 1, 32, 32),)\n",
    "onnx_program = torch.onnx.export(torch_model, example_inputs, dynamo=True)\n",
    "onnx_program.optimize()\n",
    "onnx_program.save(\"image_classifier_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3a2cde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 13:55:16,625 - onnx_export - INFO - ONNX model is valid.\n"
     ]
    }
   ],
   "source": [
    "# Run a check to ensure the model can be loaded and run\n",
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(\"image_classifier_model.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "logger.info(\"ONNX model is valid.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91370a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 13:55:16,657 - onnx_export - INFO - Input size: (1, 1, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "\n",
    "onnx_inputs = [tensor.numpy(force=True) for tensor in example_inputs]\n",
    "logger.info(f\"Input size: {onnx_inputs[0].shape}\")\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\n",
    "    \"./image_classifier_model.onnx\", providers=[\"CPUExecutionProvider\"]\n",
    ")\n",
    "\n",
    "onnxruntime_input = {\n",
    "    input_arg.name: input_value\n",
    "    for input_arg, input_value in zip(ort_session.get_inputs(), onnx_inputs)\n",
    "}\n",
    "\n",
    "# ONNX Runtime returns a list of outputs\n",
    "onnxruntime_outputs = ort_session.run(None, onnxruntime_input)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f5b38cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 13:55:16,689 - onnx_export - INFO - PyTorch and ONNX Runtime output matched!\n",
      "2025-05-28 13:55:16,690 - onnx_export - INFO - Output length: 1\n",
      "2025-05-28 13:55:16,691 - onnx_export - INFO - Sample output: [[-0.1482003   0.0178181   0.01821857  0.11436789  0.04181811 -0.04224392\n",
      "   0.03377488 -0.0180761   0.03347242 -0.0055116 ]]\n"
     ]
    }
   ],
   "source": [
    "# Lets compare with torch run\n",
    "torch_outputs = torch_model(*example_inputs)\n",
    "\n",
    "assert len(torch_outputs) == len(onnxruntime_outputs)\n",
    "for torch_output, onnxruntime_output in zip(torch_outputs, onnxruntime_outputs):\n",
    "    torch.testing.assert_close(torch_output, torch.tensor(onnxruntime_output))\n",
    "\n",
    "logger.info(\"PyTorch and ONNX Runtime output matched!\")\n",
    "logger.info(f\"Output length: {len(onnxruntime_outputs)}\")\n",
    "logger.info(f\"Sample output: {onnxruntime_outputs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
